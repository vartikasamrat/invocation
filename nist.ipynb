{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.5924\n",
      "Epoch 2/10, Loss: 1.7626\n",
      "Epoch 3/10, Loss: 2.0672\n",
      "Epoch 4/10, Loss: 1.4257\n",
      "Epoch 5/10, Loss: 1.5061\n",
      "Epoch 6/10, Loss: 1.4988\n",
      "Epoch 7/10, Loss: 1.2514\n",
      "Epoch 8/10, Loss: 1.4356\n",
      "Epoch 9/10, Loss: 1.2239\n",
      "Epoch 10/10, Loss: 1.2733\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.91      0.74        11\n",
      "         1.0       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.31      0.45      0.37        17\n",
      "weighted avg       0.40      0.59      0.48        17\n",
      "\n",
      "CNN Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 6  0]]\n",
      "CNN model saved as cnn_parkinsons_model.pth.\n",
      "Recording...\n",
      "Recording complete.\n",
      "CNN Prediction: PwPD\n",
      "Random Forest Prediction: HC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S M N RAZA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import tempfile\n",
    "from ipywidgets import Dropdown, Button, Output, VBox\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Function to list audio files in a directory\n",
    "def list_audio_files(directory):\n",
    "    return [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
    "\n",
    "# Function to extract MFCC features\n",
    "def feature_extraction(file_path):\n",
    "    x, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=22).T, axis=0)\n",
    "    mfcc_labels = [f'MFCC_Coefficient_{i+1}' for i in range(len(mfcc))]\n",
    "    return mfcc, mfcc_labels\n",
    "\n",
    "# Directories for Healthy Controls (HC) and PwPD\n",
    "hc_directory = r'C:\\Users\\S M N RAZA\\Downloads\\23849127\\HC_AH\\HC_AH'\n",
    "pwpd_directory = r'C:\\Users\\S M N RAZA\\Downloads\\23849127\\PD_AH\\PD_AH'\n",
    "\n",
    "# Extract MFCC features and prepare the dataset\n",
    "mfcc_df = pd.DataFrame()\n",
    "for label, directory in [('HC', hc_directory), ('PwPD', pwpd_directory)]:\n",
    "    for audio_file in list_audio_files(directory):\n",
    "        audio_path = os.path.join(directory, audio_file)\n",
    "        mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "        temp_df = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "        temp_df['Audio_File'] = audio_file\n",
    "        temp_df['Label'] = label\n",
    "        mfcc_df = pd.concat([mfcc_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Prepare data for model training\n",
    "X = mfcc_df.drop(columns=['Audio_File', 'Label']).values\n",
    "y = mfcc_df['Label'].map({'HC': 0, 'PwPD': 1}).values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define CNN model in PyTorch\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        \n",
    "        # Calculate flattened size dynamically\n",
    "        conv1_output_size = input_shape[0] - (3 - 1)\n",
    "        pool1_output_size = conv1_output_size // 2\n",
    "        conv2_output_size = pool1_output_size - (3 - 1)\n",
    "        pool2_output_size = conv2_output_size // 2\n",
    "        \n",
    "        self.flatten_size = 64 * pool2_output_size\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize CNN model\n",
    "input_shape = (X_train_cnn.shape[1], 1)\n",
    "cnn_model = CNNModel(input_shape)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_cnn, dtype=torch.float32).permute(0, 2, 1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_cnn, dtype=torch.float32).permute(0, 2, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Train the CNN model\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    permutation = torch.randperm(X_train_tensor.size(0))\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_X, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = cnn_model(X_test_tensor).squeeze().round()\n",
    "    print(\"CNN Classification Report:\")\n",
    "    print(classification_report(y_test_tensor.numpy(), predictions.numpy()))\n",
    "    print(\"CNN Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_tensor.numpy(), predictions.numpy()))\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cnn_model.state_dict(), 'cnn_parkinsons_model.pth')\n",
    "print(\"CNN model saved as cnn_parkinsons_model.pth.\")\n",
    "\n",
    "# Function to record live audio\n",
    "def record_audio(duration=5, sample_rate=22050):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "    print(\"Recording complete.\")\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    write(temp_file.name, sample_rate, audio)\n",
    "    return temp_file.name\n",
    "\n",
    "# Function to classify a single audio file\n",
    "def classify_audio(audio_file, model, rfc_model):\n",
    "    mfcc_features, _ = feature_extraction(audio_file)\n",
    "    input_tensor = torch.tensor(mfcc_features.reshape(1, -1, 1), dtype=torch.float32).permute(0, 2, 1)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cnn_prediction = model(input_tensor).item()\n",
    "    rfc_prediction = rfc_model.predict(mfcc_features.reshape(1, -1))[0]\n",
    "    print(f\"CNN Prediction: {'PwPD' if cnn_prediction > 0.5 else 'HC'}\")\n",
    "    print(f\"Random Forest Prediction: {'PwPD' if rfc_prediction == 1 else 'HC'}\")\n",
    "\n",
    "# Load and test live audio classification\n",
    "recorded_audio = record_audio()\n",
    "classify_audio(recorded_audio, cnn_model, joblib.load('rfc_trained_model.joblib'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
